{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c43a82",
   "metadata": {},
   "source": [
    "# Problemstatement:  Kann regelmäßiges Renditeverhalten einer Aktie für das Jahr dargestellt werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fce022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nötige librarys importieren\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import math \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc50c473",
   "metadata": {},
   "source": [
    "## Datenimport täglicher Handelsdaten einer Aktie über API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# den API-key speichern, der von der Seite frei vergeben wird.\n",
    "# der API-provider ist https://www.alphavantage.co/\n",
    "apikey = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f0272",
   "metadata": {},
   "source": [
    "### Abruf des Search-Engine des API-providers, um den Code für das börsennotierte Unternehmen zu bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eingabe des gesuchten börsennotierten Unternehmen\n",
    "company = input(\"Please enter companys name \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier werden die Parameter für den späteren request erstellt. \n",
    "params_1 = dict(apikey = apikey)\n",
    "print(params_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# den Search-URL per Stringoperationen bauen\n",
    "search_url = 'https://www.alphavantage.co/query?function=SYMBOL_SEARCH&keywords='+company\n",
    "response_search = requests.get(search_url, params =params_1)\n",
    "response_search.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten bzw. Suchergebnisse abrufen\n",
    "response_search.json()\n",
    "print(json.dumps(response_search.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2ce7e",
   "metadata": {},
   "source": [
    "### Datenabruf der täglichen Handelsdaten beim API-provider "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eingabe des gesuchten Unternehmens mit dem Symbol per copy-paste\n",
    "company_symbol = input('Please enter the companys symbol ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier werden die Parameter für den späteren request erstellt:\n",
    "# 'full', da nach Angaben des API-providers per default 'compact' 100 Tage abgerufen würden und mit 'full' alle vorhandenen.\n",
    "params_2 = dict(outputsize= 'full', apikey = apikey)\n",
    "print(params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dac8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL per Stringoperationen bauen\n",
    "url_data = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol='+company_symbol\n",
    "response_data = requests.get(url_data, params = params_2)\n",
    "response_data.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten bzw. Handelsdaten abrufen und der Variable 'data' zuordnen\n",
    "data = response_data.json()\n",
    "print(json.dumps(response_data.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515176a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary-schüssel ermitteln für weitere Verarbeitung\n",
    "response_data.json().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data clean: Metadaten brauchen wir nicht\n",
    "# dictionary-schüssel zweiter Ebene ist das Datum des Tages\n",
    "dates = data['Time Series (Daily)'].keys()\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aus dem dict machen wir ein pd.DataFrame\n",
    "companys_daily = pd.DataFrame(data['Time Series (Daily)']).T\n",
    "print(companys_daily.head())\n",
    "print(companys_daily.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77654a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Datentypen müssen für die Verarbeitung passen\n",
    "companys_daily.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für die Analyse werden hier nur die Spalte close und open gebraucht, um einen stetigen Verlauf zu gewährleisten,\n",
    "# da die beiden Spalten Preise darstellen passt der Datentyp float\n",
    "companys_daily=companys_daily.astype(float)\n",
    "companys_daily.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb049201",
   "metadata": {},
   "outputs": [],
   "source": [
    "companys_daily.sort_index(ascending=True, inplace=True)\n",
    "companys_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagesrendite = Schlusskurs - Eröffnungskurs und, da wir als Ziel haben die Jahre miteinander zu vergleichen, \n",
    "# bietet sich als Vergleichseinheit % an\n",
    "companys_daily.loc[:,'daily_return'] = 0\n",
    "for i in range(0,companys_daily.shape[0]):\n",
    "    if i == 0:\n",
    "        companys_daily.iloc[i,8] = (companys_daily.iloc[i,3]-companys_daily.iloc[i,0])/companys_daily.iloc[i,0]*100\n",
    "    else:\n",
    "        companys_daily.iloc[i,8] = (companys_daily.iloc[i,3]-companys_daily.iloc[i-1,3])/companys_daily.iloc[i-1,3]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a525e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "companys_daily.sort_index(ascending=False, inplace=True)\n",
    "companys_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wie viele fehlerhafte Einträge gibt es?\n",
    "companys_daily['daily_return'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die rohen Daten sind nun vorhanden\n",
    "print(companys_daily)\n",
    "print(companys_daily.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce64417",
   "metadata": {},
   "source": [
    "## Erstellung vom DataFrame täglicher Rendite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# für die Analyse brauchen wir nur die Tagesrenditen\n",
    "companys_daily_return=companys_daily['daily_return']\n",
    "companys_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c60ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eine erste Visualisierung zu anschauungszwecken\n",
    "fig = px.line(companys_daily_return,y='daily_return',title=company)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wie viele Handelstage haben wir im Datenimport?\n",
    "companys_daily_return.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da als nächstes die Datentransformierungen beginnen, erstmal die Daten durch eine Kopie absichern\n",
    "companys_daily_return = pd.DataFrame(companys_daily_return)\n",
    "companys_daily_return2 = companys_daily_return.copy()\n",
    "companys_daily_return2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eeadc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abfrage vom Speicher_pfad zum Speicherordner vom User-Pc\n",
    "pfad = input('Gebe den Pfad zum Ordner hier ein ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e374da",
   "metadata": {},
   "source": [
    "\n",
    "## Analyse gleichgewichteter wöchentlicher Rendite "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4fe9b",
   "metadata": {},
   "source": [
    "### Dataset Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89392a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um den Arbeitspeicher zu entlassten, slicen wir für die Analyse irrelavante Jahre weg und damit irrelevante Daten.\n",
    "# Festlegung vom abgeschlossenen Zeitintervall, auf dem die Rendite analysiert wird.\n",
    "date_end = input('Tippe die Jahrzahl ein, welche den Zeitraum von links begrenzt (empf. 3-5 Jahre Abstand zwischen den Jahreszahlen): ')\n",
    "date_end_titel = date_end\n",
    "date_end= int(date_end)\n",
    "date_start = input('Tippe die Jahrzahl ein, welche den Zeitraum von rechts begrenzt (empf. 3-5 Jahre Abstand zwischen den Jahreszahlen): ')\n",
    "date_start_titel = date_start\n",
    "date_start= int(date_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c20bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der Funktion 'date', um das Datum aus dem Index bearbeiten zu können.\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auf welchem Zeitraum werden wir slicen?\n",
    "[str(date(date_end,1,1)),str(date(date_start,12,31))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c89379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jetzt slicen wir auf das Zeitintervall\n",
    "companys_daily_return_glge = companys_daily_return2.loc[str(date(date_start,12,31)):str(date(date_end,1,1)),:].copy()\n",
    "companys_daily_return_glge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2eede1",
   "metadata": {},
   "source": [
    "### Bestimmung täglicher gleichgewichteter Rendite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zur Bearbeitung das Datum in eine Spalte aus dem Index extrahieren \n",
    "companys_daily_return_glge.reset_index(inplace=True)\n",
    "companys_daily_return_glge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e93a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# der Datentyp wird zu Datum-Format angepasst\n",
    "companys_daily_return_glge.loc[:,'index']=pd.to_datetime(companys_daily_return_glge.loc[:,'index'])\n",
    "companys_daily_return_glge.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df649c3e",
   "metadata": {},
   "source": [
    "### Bestimmung jahresübergreifender wöchentlicher Rendite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca316f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Jedem Datensatz die KW zuordnen\n",
    "companys_daily_return_glge.loc[:,'Year']= companys_daily_return_glge.loc[:,'index'].dt.isocalendar().year\n",
    "companys_daily_return_glge.loc[:,'index']= companys_daily_return_glge.loc[:,'index'].dt.isocalendar().week\n",
    "companys_daily_return_glge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f381bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dies ist nur ein  Testdurchlauf, um nachzumessen, ob der Renditeverfall zum Coronatief 2020 übereinstimmt.\n",
    "# setze hierfür das Zeitintervall auf 2020 bis 2020\n",
    "a = np.concatenate((companys_daily_return_glge.loc[companys_daily_return_glge.loc[:,'index']==7,'daily_return']/100+1,companys_daily_return_glge.loc[companys_daily_return_glge.loc[:,'index']==8,'daily_return']/100+1))\n",
    "b = np.concatenate((a,companys_daily_return_glge.loc[companys_daily_return_glge.loc[:,'index']==9,'daily_return']/100+1))\n",
    "c = np.concatenate((b,companys_daily_return_glge.loc[companys_daily_return_glge.loc[:,'index']==10,'daily_return']/100+1))\n",
    "d = np.concatenate((c,companys_daily_return_glge.loc[companys_daily_return_glge.loc[:,'index']==11,'daily_return']/100+1))\n",
    "d.prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdefc05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wie große ist das Dataset nun?\n",
    "companys_daily_return_glge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b72fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gibt es Kalenderwochen die in unserem Data set fehlen und wenn ja, welche?\n",
    "null_week = list(range(0,53-companys_daily_return_glge['index'].unique().shape[0]))\n",
    "j = 0\n",
    "for i in range(1,54):\n",
    "    if i not in companys_daily_return_glge['index'].unique():\n",
    "        null_week[j] = i\n",
    "        j +=1\n",
    "null_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatierung zum DataFrame\n",
    "null_weeks_and_return = pd.DataFrame([null_week,[0 for k in range(len(null_week))], [0 for k in range(len(null_week))]]).T\n",
    "null_weeks_and_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die fehlenden Kalenderwochen werden mit Rendite 0 hinzugefügt\n",
    "companys_daily_return_glge = pd.DataFrame(np.vstack((companys_daily_return_glge,null_weeks_and_return)))\n",
    "companys_daily_return_glge.columns = ['index','daily_return','Year']\n",
    "companys_daily_return_glge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e046020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# die KW53 ist unregelmäßig, daher wird es sinn ergeben, \n",
    "# die Häufigkeit der Wochenrenditen im dataset, um die letzte KW des Jahres zu speichern, vor dem Aggregieren nach KW\n",
    "A_KWmax = companys_daily_return_glge.loc[companys_daily_return_glge.loc[:,'index'] == companys_daily_return_glge['index'].max(),'index'].count()\n",
    "A_KW52 = companys_daily_return_glge.loc[companys_daily_return_glge.loc[:,'index'] == 52,'index'].count()\n",
    "A_KW1 = companys_daily_return_glge.loc[companys_daily_return_glge.loc[:,'index'] == 1,'index'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Datensätze einer KW und eines Jahres werden gruppiert und der daily_return durch Produktbildung aggregiert.\n",
    "companys_daily_return_glge['daily_return'] = companys_daily_return_glge['daily_return']/100 + 1\n",
    "companys_daily_return_glge = companys_daily_return_glge.groupby(['index', 'Year']).prod().reset_index()\n",
    "companys_daily_return_glge['daily_return'] = (companys_daily_return_glge['daily_return'] - 1)*100\n",
    "companys_daily_return_glge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf54644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# das Ergebnis geteilt durch die Anzahl der Jahre.\n",
    "companys_daily_return_glge = companys_daily_return_glge.drop(['Year'], axis=1)\n",
    "companys_daily_return_glge = companys_daily_return_glge.groupby(['index']).mean().reset_index()\n",
    "companys_daily_return_glge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# den wahren Index und die Kategorienspalte umbennen\n",
    "companys_daily_return_glge.columns = ['Week','weekly_return']\n",
    "companys_daily_return_glge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die KW wird zum Index\n",
    "companys_daily_return_glge.set_index('Week', inplace = True)\n",
    "companys_daily_return_glge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d31320",
   "metadata": {},
   "source": [
    "### Visualisierung wöchentlicher Rendite gleichgewichtet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de9d60",
   "metadata": {},
   "source": [
    "#### Bildung eines dreiwöchigen Mittelwerts zur Darstellung von Zeitabschnitten positiven und negativen Renditeverhaltens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafaaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für den Fall, dass der Zeitraum so gewählt ist, dass es keine KW53 gibt, wird die letzte KW in einer Variable gespeichert:\n",
    "last_week = len(companys_daily_return_glge['weekly_return'])\n",
    "last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec997e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung einer neuen Spalte mit dem dreiwöchigen Mittelwert im DataFrame vereinfacht das iterieren\n",
    "companys_daily_return_glge['drei_Wochen_Mittelwert']=0\n",
    "# Der Loop läuft nun über die Länge des DataFrames:\n",
    "for i in range(1,last_week+1):\n",
    "    # KW1 hat uneindeutige Zuordnung zur vorherigen KW, und zwar KW52 und KW53.\n",
    "    # In KW1 nimmt der Mittelwert die KW53*#KW53/(#KW52+#KW53) und KW52*#KW52/(#KW52+#KW53), \n",
    "    # somit werden KW52 und KW53 so gewichtet, dass sie dem Wert nach nur einer KW entsprechen,\n",
    "    # um das Problem der unregelmäßigen KW53 zu überwinden.\n",
    "    if i==1:\n",
    "        companys_daily_return_glge.loc[i,'drei_Wochen_Mittelwert'] = (companys_daily_return_glge.loc[52,'weekly_return']*A_KW52/(A_KW52+A_KWmax) + \n",
    "                                                                      companys_daily_return_glge.loc[last_week,'weekly_return']*A_KWmax/(A_KW52+A_KWmax) + \n",
    "                                                                      companys_daily_return_glge.loc[1,'weekly_return'] + \n",
    "                                                                      companys_daily_return_glge.loc[2,'weekly_return'])/3\n",
    "    \n",
    "    # KW52 hat uneindeutige Zuordnung zur nächsten KW, und zwar KW53 und KW1.\n",
    "    # In KW52 nimmt der Mittelwert die KW53*#KW53/(#KW1+#KW53) und KW1*#KW1/(#KW1+#KW53), \n",
    "    # somit werden KW1 und KW53 so gewichtet, dass sie dem Wert nach nur einer KW entsprechen \n",
    "    elif i==52:\n",
    "        companys_daily_return_glge.loc[i,'drei_Wochen_Mittelwert'] = (companys_daily_return_glge.loc[51,'weekly_return'] +  \n",
    "                                                                      companys_daily_return_glge.loc[52,'weekly_return'] + \n",
    "                                                                      companys_daily_return_glge.loc[last_week,'weekly_return']*A_KWmax/(A_KW1+A_KWmax) + \n",
    "                                                                      companys_daily_return_glge.loc[1,'weekly_return']*A_KW1/(A_KW1+A_KWmax))/3\n",
    "    \n",
    "    # die KW 53 hat eindeutige Zuordnung zur vorherigen und nächsten KW, \n",
    "    # ledigleich die nächste KW kann nicht im loop bestimmt werden.\n",
    "    elif i==53:   \n",
    "        companys_daily_return_glge.loc[53,'drei_Wochen_Mittelwert'] = (companys_daily_return_glge.loc[52,'weekly_return'] + \n",
    "                                                                      companys_daily_return_glge.loc[53,'weekly_return'] + \n",
    "                                                                      companys_daily_return_glge.loc[1,'weekly_return'])/3\n",
    "    \n",
    "    # sonst bildet der Loop pro Datensatz den Mittelwert von der Woche davor, von der momentanen und von der danach\n",
    "    else:\n",
    "        companys_daily_return_glge.loc[i,'drei_Wochen_Mittelwert'] = (companys_daily_return_glge.loc[i-1,'weekly_return'] + \n",
    "                                                                      companys_daily_return_glge.loc[i,'weekly_return'] + \n",
    "                                                                      companys_daily_return_glge.loc[i+1,'weekly_return'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "companys_daily_return_glge['acc_Rendite']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b744071",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "# der for-loops muss zweimal laufen, um alle akkumulierten Werten hernaziehen zu können: wegen KW1.\n",
    "while j<2:\n",
    "    # Erstellung einer neuen Spalte im DataFrame vereinfacht das iterieren\n",
    "    # Der Loop läuft nun über die Länge des DataFrames:\n",
    "    for i in range(1,last_week+1):\n",
    "        # sollte der Mittelwert zwischen dieser Woche und der nächsten und der letzten das Vorzeichen beibehalten,\n",
    "        # dann soll der Loop weiter Gewinn bzw. Verlust accumulieren, allerdings nach den Wochenrenditen, nicht nach dem Mittelwert.\n",
    "        # In KW1: nimmt der Loop die KW52 und die letzte KW wegen der unregelmäßigen KW53\n",
    "        \n",
    "        if i == 1 and np.sign(companys_daily_return_glge.loc[52,'weekly_return']*A_KW52/(A_KW52+A_KWmax)+companys_daily_return_glge.loc[last_week,'weekly_return']*A_KWmax/(A_KW52+A_KWmax)) == np.sign(companys_daily_return_glge.loc[1,'drei_Wochen_Mittelwert']) == np.sign(companys_daily_return_glge.loc[2,'drei_Wochen_Mittelwert']):\n",
    "            if companys_daily_return_glge.loc[52,'acc_Rendite']*A_KW52/(A_KW52+A_KWmax) + companys_daily_return_glge.loc[last_week,'acc_Rendite']*A_KWmax/(A_KW52+A_KWmax) == 0:\n",
    "                companys_daily_return_glge.loc[1,'acc_Rendite'] = 0\n",
    "            else:\n",
    "                companys_daily_return_glge.loc[1,'acc_Rendite'] = ((1+(companys_daily_return_glge.loc[52,'acc_Rendite']*A_KW52/(A_KW52+A_KWmax) + companys_daily_return_glge.loc[last_week,'acc_Rendite']*A_KWmax/(A_KW52+A_KWmax))/100)*(1 + companys_daily_return_glge.loc[1,'weekly_return']/100)-1)*100\n",
    "        \n",
    "        elif i == last_week and np.sign(companys_daily_return_glge.loc[last_week-1,'weekly_return']) == np.sign(companys_daily_return_glge.loc[last_week,'drei_Wochen_Mittelwert']) == np.sign(companys_daily_return_glge.loc[1,'drei_Wochen_Mittelwert']):\n",
    "            if companys_daily_return_glge.loc[last_week-1,'acc_Rendite'] == 0:\n",
    "                companys_daily_return_glge.loc[last_week,'acc_Rendite'] = 0\n",
    "            else:\n",
    "                companys_daily_return_glge.loc[last_week,'acc_Rendite'] = ((1+companys_daily_return_glge.loc[last_week-1,'acc_Rendite']/100) * (1+ companys_daily_return_glge.loc[last_week,'weekly_return']/100)-1)*100\n",
    "        elif i!=1 and i!=last_week and np.sign(companys_daily_return_glge.loc[i,'drei_Wochen_Mittelwert']) == np.sign(companys_daily_return_glge.loc[i-1,'drei_Wochen_Mittelwert']) == np.sign(companys_daily_return_glge.loc[i+1,'drei_Wochen_Mittelwert']):\n",
    "            if companys_daily_return_glge.loc[i-1,'acc_Rendite'] == 0:\n",
    "                companys_daily_return_glge.loc[i,'acc_Rendite'] = companys_daily_return_glge.loc[i,'weekly_return']\n",
    "            else:\n",
    "                companys_daily_return_glge.loc[i,'acc_Rendite'] =  ((1+companys_daily_return_glge.loc[i-1,'acc_Rendite']/100) *(1+ companys_daily_return_glge.loc[i,'weekly_return']/100)-1)*100\n",
    "        \n",
    "        # sollte der Mittelwert nächste Woche von Gewinn zu Verlust oder umgekehrt wechseln,\n",
    "        # dann soll der Loop die Akkumulierung neu bei Null beginnen, um klar Gewinn bzw. Verlustzeiträume abzugrenzen.\n",
    "        else:\n",
    "            companys_daily_return_glge.loc[i,'acc_Rendite'] = 0\n",
    "    j+=1\n",
    "companys_daily_return_glge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1a84b",
   "metadata": {},
   "source": [
    "#### Visualisierung mittels Linien- und Flächendiagramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leere Figure erstellen\n",
    "fig1 = go.Figure()\n",
    "# einen Trace der chronologisch gewichteten wöchentlichen Rendite als Liniendiagramm hinzufügen\n",
    "fig1.add_trace(go.Scatter(x=companys_daily_return_glge.index,y=companys_daily_return_glge.loc[:,'weekly_return'],\n",
    "    name=\"weekly average return  <br>(indicator for volatility)\"))\n",
    "# einen Trace des dreitägigen Mittelwerts hinzufügen\n",
    "fig1.add_trace(go.Scatter(x=companys_daily_return_glge.index,y=companys_daily_return_glge.loc[:,'drei_Wochen_Mittelwert'],fill='tozeroy',\n",
    "    name=\"three weeks average <br>(indicator for +/- return periods)\"))\n",
    "# Zur Renditeeinschätzung von Zeitperioden die in denselben akkumulierte wöchentliche Rendite\n",
    "fig1.add_trace(go.Scatter(x=companys_daily_return_glge.index,y=companys_daily_return_glge.loc[:,'acc_Rendite'],fill='tozeroy',\n",
    "    name=\"accumulated return on period <br>(indicator for orders)\"))\n",
    "# Das Layout anpassen\n",
    "fig1.update_layout(\n",
    "    title=company +' equal weighted Analysis ['+ date_end_titel +' - '+date_start_titel+'] from '+str(date.today())+ ' ',\n",
    "    xaxis_title=\"calendar week\",\n",
    "    yaxis_title=\"% return\",\n",
    "    font=dict(size=10,color=\"RebeccaPurple\"),\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02,\n",
    "                xanchor=\"right\",x=1))\n",
    "# Die Abstände der Wochen auf der Anzeige der x-Achse für bessere Lesbarkeit verkleinern\n",
    "fig1.update_xaxes(nticks=30)\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f9d84",
   "metadata": {},
   "source": [
    "#### Export des Graphen als interaktive .html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ea57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = company+'_return_analysis_'+date_end_titel +'-'+date_start_titel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1.write_html(pfad+'/'+file1 +'.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78de2fa",
   "metadata": {},
   "source": [
    "## Analyse wöchentlicher Rendite unter chronologisch abnehmender Gewichtung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f386ef",
   "metadata": {},
   "source": [
    "### Dataset Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59680cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um den Arbeitspeicher zu entlassten, slicen wir für die Analyse irrelavante Jahre weg und damit irrelevante Daten.\n",
    "# Festlegung vom abgeschlossenen Zeitintervall, auf dem die Rendite analysiert wird.\n",
    "jahre = input('Tippe die Jahresanzahl (empf. 12) für die Analyse wöchentlicher Rendite unter chronologisch fallender Gewichtung ein: ')\n",
    "jahre=int(jahre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7866c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der Funktion 'date', um das Datum aus dem Index bearbeiten zu können.\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a0fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ab wann rückwirkend slicen wir?\n",
    "date.today().year-jahre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir definieren bzw. slicen unser Dataset also von heute bis zum Datum vor 'jahre'\n",
    "companys_daily_return = companys_daily_return[str(date.today()):str(date(date.today().year-jahre,date.today().month,date.today().day))]\n",
    "companys_daily_return.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba4fec6",
   "metadata": {},
   "source": [
    "### Abnehmende Gewichtung täglicher Rendite nach Jahr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absicherung der Norm von daily_return bzw. der Abstand der einzelnen Werte von der Null\n",
    "# Dies ist wichtig, da nach der Gewichtung der Abstand zur Null  wieder hergestellt werden muss - im Sinne eines Mittelwertes\n",
    "abs_total = abs(companys_daily_return.loc[:,'daily_return']).sum()\n",
    "abs_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zur Bearbeitung das Datum in eine Spalte aus dem Index extrahieren \n",
    "companys_daily_return.reset_index(inplace=True)\n",
    "companys_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39474017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# der Datentyp wird zu Datum-Format angepasst\n",
    "companys_daily_return['index']=pd.to_datetime(companys_daily_return['index'])\n",
    "companys_daily_return.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Datensätze werden mit dem zugehörigen Jahr gekennzeichnet\n",
    "companys_daily_return['Year']= companys_daily_return['index'].dt.isocalendar().year\n",
    "companys_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontrolle: Jahre die im Dataset sind\n",
    "years = companys_daily_return['Year'].unique()\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "companys_daily_return_EMA = companys_daily_return.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7dc412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestimmung des Faktors für die Gewichtung der Daten nach exponentiellem Zerfall. \n",
    "# Ein Schrumpfaktor ergibt mehr Sinn als linearer Zerfall inspiriert am \"Exponential Smoothing\"\n",
    "# unter der Annahme, dass s_0 = (1-alpha)**t * x_0, wobei x_0 die Werte der KWs des ältesten jahres (nach 'jahre') sind.\n",
    "# (1-alpha)='rate', damit ist alpha in [0,1] klein nach Empfehlung zur Abschätzung von unten beim smoothing factor und Input.\n",
    "\n",
    "rate = round(0.1**(1/jahre),3)\n",
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86824ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Gewichtung wird mit einem Loop bestimmt, über die Länge des DataFrames:\n",
    "# anders als beim \"Exponential Smoothing\" wird hier keine Abschätzung von unten verfolgt, sondern eine Einschätzung.\n",
    "# Daher wird x_t also die Beobachtung aus dem aktuellen Jahr und dem davor nicht mit alpha verkleinert, sondern beibehalten.\n",
    "# dadurch erübrig sich auch die Problamik von der Relevanz von x_0 beim \"Exponential Smoothing\".\n",
    "# Diesbezüglich ist allerdings eine konventionelle abschätzung von oben nötig, und zwar infolge die EMA(Jahre).\n",
    "for i in range(len(companys_daily_return['Year'])):\n",
    "    # Sollte das Jahr in der Zeile i nicht das jetzige und nicht das letzte Jahr sein, dann wird gewichtet:\n",
    "   if years.max()-1-companys_daily_return.loc[i,'Year']>0:\n",
    "        # die tägliche Rendite mir der rate**(leztes_Jahr-Jahr_aus_Zeile_i).\n",
    "        companys_daily_return.loc[i,'daily_return'] = companys_daily_return.loc[i,'daily_return']*rate**(years.max()-1-companys_daily_return.loc[i,'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d87c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da das jetzige Jahr die Gewichtung 1 hat ist offensichtlich, dass die nun gewichteten Werte größer sind als ursprünglich.\n",
    "# Entsprechend müssen alle Werte normiert werden, damit eine realistische Einschätzung künftiger Rendite pro Woche entsteht. \n",
    "ge_abs_total = abs(companys_daily_return.loc[:,'daily_return']).sum()\n",
    "ge_abs_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd36042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestimmung des Faktors zur Widerherstellung des Abstandes zur Null - Normierungsfaktor:\n",
    "faktor_norm = abs_total/ge_abs_total\n",
    "# Es hat sich bewährt diese Berechnung etwas anzupassen, da die EMA deutlich größere Wert ausgibt:\n",
    "faktor_norm = faktor_norm *1.8\n",
    "faktor_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wiederherstellung des Abstandes zu Null der nun gewichteten Werte - Normierung:\n",
    "companys_daily_return.loc[:,'daily_return'] = companys_daily_return.loc[:,'daily_return']*faktor_norm\n",
    "companys_daily_return.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82baf609",
   "metadata": {},
   "source": [
    "### Bestimmung jahresübergreifender wöchentlicher Rendite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ff74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zuorndung von jedem Datensatz zu seiner KW\n",
    "companys_daily_return['index']= companys_daily_return['index'].dt.isocalendar().week\n",
    "companys_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcb3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wie große ist das Dataset nun?\n",
    "companys_daily_return.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52252205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gibt es Kalenderwochen die in unserem Data set fehlen und wenn ja, welche?\n",
    "null_week2 = list(range(0,53-companys_daily_return['index'].unique().shape[0]))\n",
    "j = 0\n",
    "for i in range(1,54):\n",
    "    if i not in companys_daily_return['index'].unique():\n",
    "        null_week2[j] = i\n",
    "        j +=1\n",
    "null_week2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatierung zum DataFrame\n",
    "null_weeks_and_return2 = pd.DataFrame([null_week2,[0 for k in range(len(null_week2))],[0 for k in range(len(null_week2))]]).T\n",
    "null_weeks_and_return2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f278d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die fehlenden Kalenderwochen werden mit Rendite 0 hinzugefügt\n",
    "companys_daily_return = pd.DataFrame(np.vstack((companys_daily_return,null_weeks_and_return2)))\n",
    "companys_daily_return.columns = ['index','daily_return','Year']\n",
    "companys_daily_return.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809bd4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# die KW53 ist unregelmäßig, daher wird es sinn ergeben, \n",
    "# die Häufigkeit der Wochenrenditen im dataset, um die letzte KW des Jahres zu speichern, vor dem Aggregieren nach KW\n",
    "A_KWmax_2 = companys_daily_return.loc[companys_daily_return.loc[:,'index'] == companys_daily_return['index'].max(),'index'].count()\n",
    "A_KW52_2 = companys_daily_return.loc[companys_daily_return.loc[:,'index'] == 52,'index'].count()\n",
    "A_KW1_2 = companys_daily_return.loc[companys_daily_return.loc[:,'index'] == 1,'index'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "companys_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce03a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Datensätze einer KW gruppieren durch arithmetischen Mittel aggregieren,\n",
    "companys_daily_return = companys_daily_return.groupby('index').mean().reset_index()\n",
    "companys_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e63c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Spalte mit dem Jahr wird nicht mehr gebraucht\n",
    "companys_daily_return = companys_daily_return.drop(['Year'], axis=1)\n",
    "companys_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd8f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# und den Spaltennamen ändern\n",
    "companys_daily_return.columns = ['Week','weekly_return']\n",
    "companys_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee50900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die KW wird Index\n",
    "companys_daily_return.set_index('Week', inplace = True)\n",
    "companys_daily_return.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28fcd6",
   "metadata": {},
   "source": [
    "#### Berechnung der EMA zu den angegebenen Jahren zur Gewichtungskontrolle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "companys_daily_return_EMA['index']= companys_daily_return_EMA['index'].dt.isocalendar().week\n",
    "companys_daily_return_EMA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3553f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Datensätze einer KW und eines Jahres werden gruppiert und der daily_return durch Produktbildung aggregiert.\n",
    "companys_daily_return_EMA['daily_return'] = companys_daily_return_EMA['daily_return']/100 + 1\n",
    "companys_daily_return_EMA = companys_daily_return_EMA.groupby(['index', 'Year']).prod().reset_index()\n",
    "companys_daily_return_EMA['daily_return'] = (companys_daily_return_EMA['daily_return'] - 1)*100\n",
    "companys_daily_return_EMA_mthd = companys_daily_return_EMA.copy()\n",
    "companys_daily_return_EMA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb8c88",
   "metadata": {},
   "source": [
    "##### Berechnung der EMA mit Formel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc770d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA(jahre), EMA=Price(t)×k+EMA(y)×(1−k)where:t=todayy=yesterdayN=number of years in EMA_k=2÷(N+1)​\n",
    "EMA_years = list(range(0,companys_daily_return_EMA.loc[:,'index'].max()))\n",
    "# j läuft die Kalenderwochen ab.\n",
    "for j in range(0,companys_daily_return_EMA.loc[:,'index'].max()):\n",
    "    # Anzahl der Jahre für die Datensätze einer Kalenderwoche vorhanden sind \n",
    "    EMA_year = list(range(0,companys_daily_return_EMA.loc[companys_daily_return_EMA['index']==j+1,'index'].count()+1))\n",
    "    # i läuft die Jahre einer Kalenderwoche ab.\n",
    "    for i in range(0,companys_daily_return_EMA.loc[companys_daily_return_EMA['index']==j+1,'index'].count()):\n",
    "        EMA_year[i+1] = companys_daily_return_EMA.loc[companys_daily_return_EMA['index']==j+1,:].iloc[i,2]*(2/(1+jahre)) + EMA_year[i]*(1-(2/(1+jahre)))\n",
    "        \n",
    "    EMA_years[j] = EMA_year[companys_daily_return_EMA.loc[companys_daily_return_EMA['index']==j+1,'index'].count()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6055abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMA_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916fcb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.array(EMA_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ce5a5",
   "metadata": {},
   "source": [
    "##### Berechnung der EMA mit der Methode .ewm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53adc713",
   "metadata": {},
   "outputs": [],
   "source": [
    "companys_daily_return_EMA_mthd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA(jahre), kann auch mit der Methode .ewm calculiert werden, spann = jahre:\n",
    "# Liste der KW\n",
    "EMA_KW_mthd = list(range(1,companys_daily_return_EMA_mthd.loc[:,'index'].max()+1))\n",
    "# j läuft die Kalenderwochen ab.\n",
    "for j in range(1,companys_daily_return_EMA_mthd.loc[:,'index'].max()+1):\n",
    "    # Liste der Jahre für die Datensätze einer Kalenderwoche vorhanden sind \n",
    "    EMA_years_mthd = list(range(1,companys_daily_return_EMA_mthd.loc[companys_daily_return_EMA_mthd['index']==j,'index'].count()+1))\n",
    "    # Jahre einer Kalenderwoche ab.\n",
    "    EMA_KW_mthd[j-1] = list(companys_daily_return_EMA_mthd.loc[companys_daily_return_EMA_mthd['index']==j,:].iloc[:,2].ewm(span = len(EMA_years_mthd), adjust = False).mean())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c508f",
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.array(EMA_KW_mthd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e24bc",
   "metadata": {},
   "source": [
    "##### Vergleich der EMA-Berechnung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMA_compare = pd.DataFrame()\n",
    "EMA_compare['EMA_year'] = pd.array(EMA_years)\n",
    "EMA_compare['EMA_year_method'] = pd.array(EMA_KW_mthd)\n",
    "EMA_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich beider EMA-Berechnungen\n",
    "# Leere Figure erstellen\n",
    "fig1 = go.Figure()\n",
    "# einen Trace der chronologisch gewichteten wöchentlichen Rendite als Liniendiagramm hinzufügen\n",
    "fig1.add_trace(go.Scatter(x=EMA_compare.index,y=EMA_compare['EMA_year'], name=\"EMA_year\"))\n",
    "# einen Trace des dreitägigen Mittelwerts hinzufügen\n",
    "fig1.add_trace(go.Scatter(x=EMA_compare.index,y=EMA_compare['EMA_year_method'], name=\"EMA_year_method\"))\n",
    "# Das Layout anpassen\n",
    "fig1.update_layout(\n",
    "    title='EMA Vergleich',\n",
    "    xaxis_title=\"calendar week\",\n",
    "    yaxis_title=\"% return\",\n",
    "    font=dict(size=10,color=\"RebeccaPurple\"),\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02,\n",
    "                xanchor=\"right\",x=1))\n",
    "# Die Abstände der Wochen auf der Anzeige der x-Achse für bessere Lesbarkeit verkleinern\n",
    "fig1.update_xaxes(nticks=30)\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2501bee",
   "metadata": {},
   "source": [
    "### Visualisierung wöchentlicher Rendite unter chronologisch abnehmender Gewichtung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c35b20",
   "metadata": {},
   "source": [
    "#### Bildung eines dreiwöchigen Mittelwerts zur Darstellung von Zeitabschnitten positiven und negativen Renditeverhaltens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5217d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für den Fall, dass der Zeitraum so gewählt ist, dass es keine KW53 gibt, wird die letzte KW in einer Variable gespeichert:\n",
    "last_week2 = len(companys_daily_return['weekly_return'])\n",
    "last_week2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c53405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung einer neuen Spalte mit dem dreiwöchigen Mittelwert im DataFrame vereinfacht das iterieren\n",
    "# die letzte kalenderwoche im Dataset, KW1, KW52 und KW53 sind Sonderfälle\n",
    "companys_daily_return['drei_Wochen_Mittelwert']=0\n",
    "# Der Loop läuft nun über die Länge des DataFrames:\n",
    "for i in range(1,last_week2+1):\n",
    "    # KW1 hat uneindeutige Zuordnung zur vorherigen KW, und zwar KW52 und KW53.\n",
    "    # In KW1 nimmt der Mittelwert die KW53*#KW53/(#KW52+#KW53) und KW52*#KW52/(#KW52+#KW53), \n",
    "    # somit werden KW52 und KW53 so gewichtet, dass sie dem Wert nach nur einer KW entsprechen,\n",
    "    # um das Problem der unregelmäßigen KW53 zu überwinden.\n",
    "    if i==1:\n",
    "        companys_daily_return.loc[i,'drei_Wochen_Mittelwert'] = (companys_daily_return.loc[52,'weekly_return']*A_KW52_2/(A_KW52_2+A_KWmax_2) + \n",
    "                                                                      companys_daily_return.loc[last_week2,'weekly_return']*A_KWmax_2/(A_KW52_2+A_KWmax_2) + \n",
    "                                                                      companys_daily_return.loc[1,'weekly_return'] + \n",
    "                                                                      companys_daily_return.loc[2,'weekly_return'])/3\n",
    "    \n",
    "    # KW52 hat uneindeutige Zuordnung zur nächsten KW, und zwar KW53 und KW1.\n",
    "    # In KW52 nimmt der Mittelwert die KW53*#KW53/(#KW1+#KW53) und KW1*#KW1/(#KW1+#KW53), \n",
    "    # somit werden KW1 und KW53 so gewichtet, dass sie dem Wert nach nur einer KW entsprechen \n",
    "    elif i==52:\n",
    "        companys_daily_return.loc[i,'drei_Wochen_Mittelwert'] = (companys_daily_return.loc[51,'weekly_return'] +  \n",
    "                                                                    companys_daily_return.loc[52,'weekly_return'] + \n",
    "                                                                    companys_daily_return.loc[last_week2,'weekly_return']*A_KWmax_2/(A_KW1_2+A_KWmax_2) + \n",
    "                                                                    companys_daily_return.loc[1,'weekly_return']*A_KW1_2/(A_KW1_2+A_KWmax_2))/3\n",
    "    \n",
    "    # die KW 53 hat eindeutige Zuordnung zur vorherigen und nächsten KW, \n",
    "    # ledigleich die nächste KW kann nicht im loop bestimmt werden.\n",
    "    elif i==53:   \n",
    "        companys_daily_return.loc[53,'drei_Wochen_Mittelwert'] = (companys_daily_return.loc[52,'weekly_return'] + \n",
    "                                                                    companys_daily_return.loc[53,'weekly_return'] + \n",
    "                                                                    companys_daily_return.loc[1,'weekly_return'])/3\n",
    "    \n",
    "    # sonst bildet der Loop pro Datensatz den Mittelwert von der Woche davor, von der momentanen und von der danach\n",
    "    else:\n",
    "        companys_daily_return.loc[i,'drei_Wochen_Mittelwert'] = (companys_daily_return.loc[i-1,'weekly_return'] + \n",
    "                                                                      companys_daily_return.loc[i,'weekly_return'] + \n",
    "                                                                      companys_daily_return.loc[i+1,'weekly_return'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "companys_daily_return['acc_Rendite']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cad40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "# der for-loops muss zweimal laufen, um alle akkumulierten Werten hernaziehen zu können: wegen KW1.\n",
    "while j<2:\n",
    "    # Erstellung einer neuen Spalte im DataFrame vereinfacht das iterieren\n",
    "    # Der Loop läuft nun über die Länge des DataFrames:\n",
    "    for i in range(1,last_week2+1):\n",
    "        # sollte der Mittelwert zwischen dieser Woche und der nächsten und der letzten das Vorzeichen beibehalten,\n",
    "        # dann soll der Loop weiter Gewinn bzw. Verlust accumulieren, allerdings nach den Wochenrenditen, nicht nach dem Mittelwert.\n",
    "        # In KW1: nimmt der Loop die KW52 und die letzte KW wegen der unregelmäßigen KW53\n",
    "        \n",
    "        if i == 1 and np.sign(companys_daily_return.loc[52,'weekly_return']*A_KW52_2/(A_KW52_2+A_KWmax_2)+companys_daily_return.loc[last_week2,'weekly_return']*A_KWmax_2/(A_KW52_2+A_KWmax_2)) == np.sign(companys_daily_return.loc[1,'drei_Wochen_Mittelwert']) == np.sign(companys_daily_return.loc[2,'drei_Wochen_Mittelwert']):\n",
    "            if companys_daily_return.loc[52,'acc_Rendite']*A_KW52_2/(A_KW52_2+A_KWmax_2) + companys_daily_return.loc[last_week2,'acc_Rendite']*A_KWmax_2/(A_KW52_2+A_KWmax_2) == 0:\n",
    "                companys_daily_return.loc[1,'acc_Rendite'] = companys_daily_return.loc[1,'weekly_return']\n",
    "            else:\n",
    "                companys_daily_return.loc[1,'acc_Rendite'] = ((1+(companys_daily_return.loc[52,'acc_Rendite']*A_KW52_2/(A_KW52_2+A_KWmax_2) + companys_daily_return.loc[last_week2,'acc_Rendite']*A_KWmax_2/(A_KW52_2+A_KWmax_2))/100)*(1 + companys_daily_return.loc[1,'weekly_return']/100)-1)*100\n",
    "        \n",
    "        elif i == last_week2 and np.sign(companys_daily_return.loc[last_week2-1,'weekly_return']) == np.sign(companys_daily_return.loc[last_week2,'drei_Wochen_Mittelwert']) == np.sign(companys_daily_return.loc[1,'drei_Wochen_Mittelwert']):\n",
    "            if companys_daily_return.loc[last_week2-1,'acc_Rendite'] == 0:\n",
    "                companys_daily_return.loc[last_week2,'acc_Rendite'] = companys_daily_return.loc[last_week2,'weekly_return']\n",
    "            else:\n",
    "                companys_daily_return.loc[last_week2,'acc_Rendite'] = ((1+companys_daily_return.loc[last_week2-1,'acc_Rendite']/100) * (1+ companys_daily_return.loc[last_week2,'weekly_return']/100)-1)*100\n",
    "                \n",
    "        elif i!=1 and i!=last_week2 and np.sign(companys_daily_return.loc[i,'drei_Wochen_Mittelwert']) == np.sign(companys_daily_return.loc[i-1,'drei_Wochen_Mittelwert']) == np.sign(companys_daily_return.loc[i+1,'drei_Wochen_Mittelwert']):\n",
    "            if companys_daily_return.loc[i-1,'acc_Rendite'] == 0:\n",
    "                companys_daily_return.loc[i,'acc_Rendite'] = companys_daily_return.loc[i,'weekly_return']\n",
    "            else:\n",
    "                companys_daily_return.loc[i,'acc_Rendite'] =  ((1+companys_daily_return.loc[i-1,'acc_Rendite']/100) *(1+ companys_daily_return.loc[i,'weekly_return']/100)-1)*100\n",
    "        \n",
    "        # sollte der Mittelwert nächste Woche von Gewinn zu Verlust oder umgekehrt wechseln,\n",
    "        # dann soll der Loop die Akkumulierung neu bei Null beginnen, um klar Gewinn bzw. Verlustzeiträume abzugrenzen.\n",
    "        else:\n",
    "            companys_daily_return.loc[i,'acc_Rendite'] = 0\n",
    "    j+=1\n",
    "companys_daily_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff227e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wir füden die EMA zur Kontrolle noch der Tabelle hinzu\n",
    "companys_daily_return['EMA_year'] = (pd.array(EMA_years)+pd.array(EMA_KW_mthd))/2\n",
    "companys_daily_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b053d1",
   "metadata": {},
   "source": [
    "#### Visualisierung mittels Linien- und Flächendiagramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leere Figure erstellen\n",
    "fig2 = go.Figure()\n",
    "# einen Trace der chronologisch gewichteten wöchentlichen Rendite als Liniendiagramm hinzufügen\n",
    "fig2.add_trace(go.Scatter(x=companys_daily_return.index,y=companys_daily_return.loc[:,'weekly_return'],\n",
    "    name=\"weekly weighted average return  <br>(indicator for volatility)\"))\n",
    "# einen Trace des dreitägigen Mittelwerts hinzufügen\n",
    "fig2.add_trace(go.Scatter(x=companys_daily_return.index,y=companys_daily_return.loc[:,'EMA_year'],\n",
    "    name=\"EMA \"+str(jahre)+\" years <br>(control of weekly weighted average return)\"))\n",
    "# einen Trace des dreitägigen Mittelwerts hinzufügen\n",
    "fig2.add_trace(go.Scatter(x=companys_daily_return.index,y=companys_daily_return.loc[:,'drei_Wochen_Mittelwert'],fill='tozeroy',\n",
    "    name=\"three weeks average <br>(indicator for +/- return periods)\"))\n",
    "# Zur Renditeeinschätzung von Zeitperioden die in denselben akkumulierte gewichtete wöchentliche Rendite\n",
    "fig2.add_trace(go.Scatter(x=companys_daily_return.index,y=companys_daily_return.loc[:,'acc_Rendite'],fill='tozeroy',\n",
    "    name=\"accumulated return on period <br>(indicator for orders)\"))\n",
    "# Das Layout anpassen\n",
    "fig2.update_layout(\n",
    "    title=company+' retrospective weighted Analysis ('+str(jahre) +' years, chronological decay factor = ' + str(rate) +')' +' from '+str(date.today())+ ' ',\n",
    "    xaxis_title=\"calendar week\",\n",
    "    yaxis_title=\"% return\",\n",
    "    font=dict(size=10,color=\"RebeccaPurple\"),\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02,\n",
    "                xanchor=\"right\",x=1))\n",
    "# Die Abstände der Wochen auf der Anzeige der x-Achse für bessere Lesbarkeit verkleinern\n",
    "fig2.update_xaxes(nticks=30)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9419a8f",
   "metadata": {},
   "source": [
    "#### Export des Graphen als interaktive .html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abfrage vom Speicher_pfad zum Speicherordner  \n",
    "file2 = company+'_retrospective_return_analysis_'+ str(jahre) +'_years'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern unter dem Speicher_pfad + Datei (per Stringoperationen gebaut)\n",
    "fig2.write_html(pfad+'/'+file2 +'.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e79a2",
   "metadata": {},
   "source": [
    "## Crossanalyse wöchentlicher Rendite chronologisch abnehmender Gewichtung und Gleichgewichtung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sum(abs(companys_daily_return['drei_Wochen_Mittelwert']))\n",
    "a_glge = sum(abs(companys_daily_return_glge['drei_Wochen_Mittelwert']))\n",
    "if a<a_glge:\n",
    "    companys_daily_return['drei_Wochen_Mittelwert'] = companys_daily_return['drei_Wochen_Mittelwert']*a_glge/a\n",
    "    companys_daily_return['acc_Rendite'] = companys_daily_return['acc_Rendite']*a_glge/a\n",
    "else:\n",
    "    companys_daily_return_glge['drei_Wochen_Mittelwert'] = companys_daily_return_glge['drei_Wochen_Mittelwert']*a/a_glge\n",
    "    companys_daily_return_glge['acc_Rendite'] = companys_daily_return_glge['acc_Rendite']*a/a_glge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c5faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevante Daten für die Crossanalyse zwischen der wöchentlichen Rendite \n",
    "# unter chronologisch abnehmender Gewichtung und unter Gleichgewichtung sind:\n",
    "# der Mittelwert von den beiden drei_Wochen_Mittelwert, sodass ein Kontrollverlauf der Zeiträume akkumuluriender Rendite besteht,\n",
    "# die beiden acc_Rendite_ge und acc_Rendite_glge bzw. akkumulierenden Renditen\n",
    "# eine Spalte für die Übereinstimmung der relevanten Daten, und zwar die acc_Rendite_cross akkumulierende Rendite beider Analysen.\n",
    "cross_weekly_return = pd.DataFrame([companys_daily_return['drei_Wochen_Mittelwert']+companys_daily_return_glge['drei_Wochen_Mittelwert'],companys_daily_return['acc_Rendite'],companys_daily_return_glge['acc_Rendite']]).T\n",
    "cross_weekly_return.columns = ['drei_Wochen_Mittelwert','acc_Rendite_ge','acc_Rendite_glge']\n",
    "cross_weekly_return.loc[:,'acc_Rendite_cross']=0\n",
    "cross_weekly_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b96620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition erster Bedingung, unter derer Erfüllung acc_Rendite_cross berechnet werden darf:\n",
    "# sollte die kleinste acc_Rendite um 99% von der größten acc_Rednite im Datensatz entfernt sein, folgt wahr. \n",
    "# Hintergrund ist, dass sehr kleine Werte irrelevant für eine Abschätzung der Rendite sind, \n",
    "def rel_dist(i):\n",
    "    quot = min(abs(cross_weekly_return.loc[i,'acc_Rendite_ge']), abs(cross_weekly_return.loc[i,'acc_Rendite_glge'])) / max(abs(cross_weekly_return.loc[i,'acc_Rendite_ge']), abs(cross_weekly_return.loc[i,'acc_Rendite_glge']))\n",
    "    return quot <0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Ausschlusskriterium:\n",
    "# Sollten die beiden acc_Rendite im Datensatz ein unterschiedliches Vorzeichen haben \n",
    "# und keiner der beiden im Verhältnis zum anderen sehr klein sein,\n",
    "# dann lässt sich nicht auf eine Renditeübereinstimmung schließen und diese sollte mit 0 bewertet werden.\n",
    "# Der folgende Loop ist die Negation obiger Aussage.\n",
    "for i in range(1,len(cross_weekly_return['acc_Rendite_ge'])):\n",
    "    if np.sign(cross_weekly_return.loc[i,'acc_Rendite_ge']) == np.sign(cross_weekly_return.loc[i,'acc_Rendite_glge']) or rel_dist(i):\n",
    "        cross_weekly_return.loc[i,'acc_Rendite_cross']=(cross_weekly_return.loc[i,'acc_Rendite_ge'] + cross_weekly_return.loc[i,'acc_Rendite_glge'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f478bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Ausschlusskriterium: Die kleinsten Werte, unter 10% des größten Wertes, sollen in der Crossanalyse unberücksichtigt beliben.\n",
    "# 3.Ausschlusskriterium: Werte mit anderer Tendenz als der drei_Wochen_Mittelwert sollen in der Crossanalyse unberücksichtigt beliben.\n",
    "for i in range(1,len(cross_weekly_return['acc_Rendite_ge'])):\n",
    "    if abs(cross_weekly_return.loc[i,'acc_Rendite_cross']) < abs(cross_weekly_return['acc_Rendite_cross'].max())*0.1 or np.sign(cross_weekly_return.loc[i,'acc_Rendite_cross']) != np.sign(cross_weekly_return.loc[i,'drei_Wochen_Mittelwert']):\n",
    "        cross_weekly_return.loc[i,'acc_Rendite_cross'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_weekly_return.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786850e",
   "metadata": {},
   "source": [
    "#### Visualisierung mittels Linien- und Flächendiagramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leere Figure erstellen\n",
    "fig3 = go.Figure()\n",
    "# einen Trace des dreitägigen Mittelwerts hinzufügen zur Kontrolle von Tendenzen\n",
    "fig3.add_trace(go.Scatter(x=cross_weekly_return.index,y=cross_weekly_return.loc[:,'drei_Wochen_Mittelwert'],\n",
    "    name=\"three weeks average <br>(indicator for +/- return periods)\"))\n",
    "# Zur Renditeeinschätzung von Zeitperioden akkumulierte gewichtete wöchentliche Rendite\n",
    "fig3.add_trace(go.Scatter(x=cross_weekly_return.index,y=cross_weekly_return.loc[:,'acc_Rendite_cross'],fill='tozeroy',\n",
    "    name=\"return on period <br>(indicator for orders)\"))\n",
    "# Das Layout anpassen\n",
    "fig3.update_layout(\n",
    "    title=company+' Crossanalysis ['+ date_end_titel +' - '+date_start_titel+'] and the last '+ str(jahre) +' years' +' from '+str(date.today())+ ' ',\n",
    "    xaxis_title=\"calendar week\",\n",
    "    yaxis_title=\"% return\",\n",
    "    font=dict(size=10,color=\"RebeccaPurple\"),\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02,\n",
    "                xanchor=\"right\",x=1))\n",
    "# Die Abstände der Wochen auf der Anzeige der x-Achse für bessere Lesbarkeit verkleinern\n",
    "fig3.update_xaxes(nticks=30)\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2093a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abfrage vom Speicher_pfad zum Speicherordner  \n",
    "file3 = company+'_return_crossanalysis_'+ date_end_titel +'-'+date_start_titel+ '_'+str(jahre) +'_years'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern unter dem Speicher_pfad + Datei (per Stringoperationen gebaut)\n",
    "fig3.write_html(pfad+'/'+file3 +'.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14342da7",
   "metadata": {},
   "source": [
    "#### Export einer Datentabelle der Crossanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_weekly_return = cross_weekly_return.round(2)\n",
    "cross_weekly_return.reset_index(inplace=True)\n",
    "cross_weekly_return.columns = ['week',company + ' average return cross %',company + ' acc return weighted ' +str(jahre) +' years %',company + ' acc return '+ date_end_titel +'-'+date_start_titel +' %' , company + ' return cross on period %']\n",
    "cross_weekly_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_weekly_return.to_excel(pfad+'/'+file3 +'.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5497ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_weekly_return.to_html(pfad+'/'+file3 +'_table.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
